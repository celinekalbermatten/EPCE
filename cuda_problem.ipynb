{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import EPCE\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from data_loader import HDRDataset\n",
    "from model import FHDR\n",
    "import potions\n",
    "from util import (\n",
    "    load_checkpoint,\n",
    "    make_required_directories,\n",
    "    mu_tonemap,\n",
    "    save_checkpoint,\n",
    "    save_hdr_image,\n",
    "    save_ldr_image,\n",
    "    update_lr,\n",
    "    plot_losses\n",
    "\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Information about GPUs -> DELETE later\n",
    "# ======================================\n",
    "\n",
    "import pynvml\n",
    "\n",
    "def get_gpu_info():\n",
    "    pynvml.nvmlInit()\n",
    "    device_count = pynvml.nvmlDeviceGetCount()\n",
    "    gpu_info = []\n",
    "    \n",
    "    for i in range(device_count):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "        gpu_memory = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        \n",
    "        gpu_info.append({\n",
    "            \"index\": i,\n",
    "            \"name\": gpu_name,\n",
    "            \"memory_total\": gpu_memory.total,\n",
    "            \"memory_used\": gpu_memory.used,\n",
    "            \"memory_free\": gpu_memory.free\n",
    "        })\n",
    "    \n",
    "    pynvml.nvmlShutdown()\n",
    "    return gpu_info\n",
    "\n",
    "# Retrieve and print GPU information including free memory\n",
    "gpu_info = get_gpu_info()\n",
    "for gpu in gpu_info:\n",
    "    print(f\"GPU {gpu['index']} Name: {gpu['name']}\")\n",
    "    print(f\"   Total Memory: {gpu['memory_total'] / 1024**2} MB\")\n",
    "    print(f\"   Used Memory : {gpu['memory_used'] / 1024**2} MB\")\n",
    "    print(f\"   Free Memory : {gpu['memory_free'] / 1024**2} MB\")\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the training options\n",
    "opt = potions.Options().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Load the data\n",
    "# ======================================\n",
    "\n",
    "dataset = HDRDataset(mode=\"train\", opt=opt)\n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# create separate data loaders for training and validation\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False)\n",
    "\n",
    "# print the number of training and validation samples\n",
    "print(\"Training samples: \", len(train_data_loader))\n",
    "print(\"Validation samples: \", len(val_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Model initialization\n",
    "# ========================================\n",
    "\n",
    "# curve estimation model\n",
    "model = EPCE.PPVisionTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Initialization of losses and optimizer\n",
    "# ========================================\n",
    "\n",
    "# define the loss function\n",
    "l1 = torch.nn.L1Loss()\n",
    "# TODO: could be \n",
    "#perceptual_loss = VGGLoss()\n",
    "perceptual_loss = EPCE.VGGLoss()\n",
    "# define the optimizer\n",
    "# TODO: could be\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Load the checkpoints if continuing training\n",
    "# ==================================================\n",
    "\n",
    "print(opt)\n",
    "\n",
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, model = load_checkpoint(model, opt.ckpt_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Checkpoint not found!\")\n",
    "        #start_epoch = 1\n",
    "        #model.apply(weights_init)\n",
    "else:\n",
    "    #start_epoch = 1\n",
    "    #model.apply(weights_init)\n",
    "    # TODO: \n",
    "    print('else cest pas biengggggg')\n",
    "\n",
    "if opt.print_model:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete later\n",
    "# print information about CUDA devices\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# ========================================\n",
    "# GPU configuration\n",
    "# ========================================\n",
    "\n",
    "# set the device -> CPU or GPU \n",
    "device = torch.device(\"cuda\")\n",
    "# move the model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Training\n",
    "# ========================================\n",
    "\n",
    "# TODO: maybe not necessary\n",
    "# set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# define the number of epochs\n",
    "opt.epochs = 200\n",
    "num_epochs = 200\n",
    "print(f\"# of epochs: {num_epochs}\")\n",
    "\n",
    "# initalize the loss lists\n",
    "losses_train = []\n",
    "losses_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt.epochs):\n",
    "    print(f\"-------------- Epoch # {epoch} --------------\")\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # check whether the learning rate needs to be updated\n",
    "    if epoch > opt.lr_decay_after:\n",
    "        update_lr(optimizer, epoch, opt)\n",
    "        \n",
    "    losses_epoch = []\n",
    "\n",
    "    # training loop\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        # move the batch to the device\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get the LDR images\n",
    "        input = batch['ldr_image']\n",
    "        input = input.to(device)\n",
    "\n",
    "        # get the HDR images\n",
    "        output_true = batch['hdr_image']\n",
    "        output_true = output_true.to(device)\n",
    "\n",
    "        # forward pass through the model\n",
    "        output = model(input)\n",
    "\n",
    "        l1_loss = 0\n",
    "        vgg_loss = 0\n",
    "\n",
    "        # compute the loss for the generated outputs\n",
    "        for i in range(len(output)):\n",
    "            l1_loss += l1(output[i], output_true[i])\n",
    "            vgg_loss += perceptual_loss(output[i], output_true[i])\n",
    "\n",
    "        # average over n iterations\n",
    "        l1_loss /= len(output)\n",
    "        vgg_loss /= len(output)\n",
    "\n",
    "        # average over batches\n",
    "        l1_loss = torch.mean(l1_loss)\n",
    "        vgg_loss = torch.mean(vgg_loss)\n",
    "\n",
    "        # TODO: why do we have FHDR loss function here?\n",
    "        # FHDR loss function\n",
    "        loss = l1_loss + (vgg_loss * 10)\n",
    "        losses_epoch.append(loss.item())\n",
    "\n",
    "        # backpropagate and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # output is the final reconstructed image so last in the array of outputs of n iterations\n",
    "        output = output[-1]\n",
    "\n",
    "        # backpropagate and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # save the results\n",
    "        if (batch + 1) % opt.save_results_after == 0: \n",
    "            save_ldr_image(img_tensor=input, batch=0, path=\"./training_results/ldr_e_{}_b_{}.jpg\".format(epoch, batch + 1),)\n",
    "            \n",
    "            save_hdr_image(img_tensor=output, batch=0, path=\"./training_results/generated_hdr_e_{}_b_{}.hdr\".format(epoch, batch + 1),)\n",
    "            \n",
    "            save_hdr_image(img_tensor=output_true, batch=0, path=\"./training_results/gt_hdr_e_{}_b_{}.hdr\".format(epoch, batch + 1),)\n",
    "    \n",
    "\n",
    "    print(f\"Training loss: {losses_epoch[-1]}\")\n",
    "    losses_train.append(losses_epoch[-1])\n",
    "\n",
    "    # average loss for the epoch\n",
    "    # TODO: maybe this could also work (new)\n",
    "    #average_loss = total_loss / len(train_data_loader)\n",
    "    #losses_train.append(average_loss)\n",
    "\n",
    "# ========================================\n",
    "# Validation\n",
    "# ========================================\n",
    "\n",
    "    # validation loop -> set the model mode to evaluation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for val_batch, val_data in enumerate(val_data_loader):\n",
    "\n",
    "            # get the LDR images\n",
    "            input_val = val_data['ldr_image']\n",
    "            input_val = input_val.to(device)\n",
    "\n",
    "            # get the HDR images\n",
    "            ground_truth_val = val_data['hdr_image']\n",
    "            ground_truth_val = ground_truth_val.to(device)\n",
    "\n",
    "            output_val = model(input_val)\n",
    "\n",
    "            # calculate the validation loss\n",
    "            l1_loss_val = 0\n",
    "            vgg_loss_val = 0\n",
    "\n",
    "            for image_val in output_val:\n",
    "                l1_loss_val += l1(image_val, ground_truth_val)\n",
    "                vgg_loss_val += perceptual_loss(image_val, ground_truth_val)\n",
    "\n",
    "\n",
    "            \"\"\"for i in range(len(output_val)):\n",
    "              l1_loss_val += l1(output_val[i],ground_truth_val[i])\n",
    "              vgg_loss_val += perceptual_loss(output_val[i], ground_truth_val[i])\n",
    "              \"\"\"\n",
    "\n",
    "            # average over n iterations\n",
    "            l1_loss_val /= len(output_val)\n",
    "            vgg_loss_val /= len(output_val)\n",
    "\n",
    "            # average over batches\n",
    "            l1_loss_val = torch.mean(l1_loss_val)\n",
    "            vgg_loss_val = torch.mean(vgg_loss_val)\n",
    "\n",
    "            # final loss function\n",
    "            val_loss = l1_loss_val + (vgg_loss_val * 10)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    # calculate average validation loss for the entire validation dataset\n",
    "    average_val_loss = sum(val_losses) / len(val_losses)\n",
    "    print(f\"Average validation Loss: {average_val_loss}\")\n",
    "    losses_validation.append(average_val_loss)\n",
    "\n",
    "    # set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_finish = time.time()\n",
    "    time_taken = (epoch_finish - epoch_start)\n",
    "\n",
    "    print(\"End of epoch {}. Time taken: {} s.\".format(epoch, int(time_taken)))\n",
    "\n",
    "    # save the checkpoints for each epoch\n",
    "    save_checkpoint(epoch, model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
